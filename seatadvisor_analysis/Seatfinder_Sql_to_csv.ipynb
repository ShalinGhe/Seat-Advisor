{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc56b89",
   "metadata": {},
   "source": [
    "\n",
    "# Seatfinder – Auswertung aus PostgreSQL-SQL-Dump (2016–2024)\n",
    "\n",
    "**Hinweis:** Dieses Notebook benötigt **nur die `.sql`-Dump-Datei** (mit `CREATE TABLE` + `COPY ... FROM stdin;` Blöcken). Es verwendet **keine** Datenbankverbindung – der Dump wird direkt geparst und in `pandas`-DataFrames geladen.\n",
    "\n",
    "**Was du tun musst:**  \n",
    "1. Lege deine Dump-Datei (z. B. `seatfinder_dump.sql`) im gleichen Ordner ab, in dem du dieses Notebook startest, oder passe unten den Pfad in `SQL_DUMP_PATH` an.  \n",
    "2. Führe die Zellen nacheinander aus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81067564",
   "metadata": {},
   "source": [
    "# Data Loading to Data Frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "510559d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL-Dump gefunden: data/seatfinder_tuebingen_2024-10-15.sql\n"
     ]
    }
   ],
   "source": [
    "SQL_DUMP_PATH = \"data/seatfinder_tuebingen_2024-10-15.sql\" \n",
    "\n",
    "import os, io, re, csv, datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Matplotlib Defaults – (keine Styles/keine Farben explizit setzen)\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (9, 4.5),\n",
    "    \"axes.grid\": True\n",
    "})\n",
    "\n",
    "assert os.path.exists(SQL_DUMP_PATH), f\"SQL_DUMP_PATH nicht gefunden: {SQL_DUMP_PATH}\"\n",
    "print(\"SQL-Dump gefunden:\", SQL_DUMP_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbf566d",
   "metadata": {},
   "source": [
    "\n",
    "## Dump-Parser (COPY-Blöcke → DataFrames)\n",
    "\n",
    "Der Parser liest `COPY schema.table (cols...) FROM stdin;` und sammelt die Tab-getrennten Datenzeilen bis zur Zeile `\\.`.  \n",
    "Leere Werte werden als `NaN` gesetzt, `\\N` wird ebenfalls zu `NaN`. Datentypen werden später konvertiert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bf05081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found COPY-Tables: ['public.locations', 'public.manual_counts', 'public.seat_estimates', 'public.wlan_clients']\n"
     ]
    }
   ],
   "source": [
    "import io, re\n",
    "    \n",
    "COPY_START_RE = re.compile(r'^COPY\\s+([a-zA-Z0-9_\\.\"]+)\\s*\\((.*?)\\)\\s+FROM\\s+stdin;', re.IGNORECASE)\n",
    "COPY_END = r'\\.'\n",
    "\n",
    "def parse_sql_dump_to_tables(sql_path):\n",
    "    tables = {}  # key: full table name (e.g., public.locations) -> dict with keys: columns, rows\n",
    "    current = None\n",
    "    cols = []\n",
    "    rows = []\n",
    "    with io.open(sql_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for raw_line in f:\n",
    "            line = raw_line.rstrip(\"\\n\")\n",
    "            if current is None:\n",
    "                m = COPY_START_RE.match(line)\n",
    "                if m:\n",
    "                    current = m.group(1)  # e.g., public.locations\n",
    "                    col_str = m.group(2)\n",
    "                    cols = [c.strip().strip('\"') for c in col_str.split(\",\")]\n",
    "                    rows = []\n",
    "            else:\n",
    "                if line == COPY_END:\n",
    "                    tables.setdefault(current, {\"columns\": cols, \"rows\": []})\n",
    "                    tables[current][\"rows\"].extend(rows)\n",
    "                    current = None\n",
    "                    cols = []\n",
    "                    rows = []\n",
    "                else:\n",
    "                    parts = line.split(\"\\t\")\n",
    "                    if len(parts) < len(cols):\n",
    "                        parts += [\"\"] * (len(cols) - len(parts))\n",
    "                    elif len(parts) > len(cols):\n",
    "                        parts = parts[:len(cols)]\n",
    "                    parts = [None if p == r\"\\N\" else p for p in parts]\n",
    "                    rows.append(parts)\n",
    "    return tables\n",
    "\n",
    "tables = parse_sql_dump_to_tables(SQL_DUMP_PATH)\n",
    "print(\"Found COPY-Tables:\", list(tables.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609dba19",
   "metadata": {},
   "source": [
    "\n",
    "## DataFrames bauen\n",
    "\n",
    "Wir ziehen die vier relevanten Tabellen in DataFrames:\n",
    "- `public.locations`\n",
    "- `public.seat_estimates`\n",
    "- `public.wlan_clients`\n",
    "- `public.manual_counts` (falls vorhanden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1faed11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locations: (20, 14)\n",
      "seat_estimates: (8323622, 5)\n",
      "wlan_clients: (17489095, 4)\n",
      "manual_counts: (1177, 5)\n"
     ]
    }
   ],
   "source": [
    "def table_to_df(tables, key):\n",
    "    t = tables.get(key)\n",
    "    if not t:\n",
    "        return None\n",
    "    df = pd.DataFrame(t[\"rows\"], columns=t[\"columns\"])\n",
    "    return df\n",
    "\n",
    "locations = table_to_df(tables, \"public.locations\")\n",
    "seat_estimates = table_to_df(tables, \"public.seat_estimates\")\n",
    "wlan_clients = table_to_df(tables, \"public.wlan_clients\")\n",
    "manual_counts = table_to_df(tables, \"public.manual_counts\")\n",
    "\n",
    "for name, df in [(\"locations\", locations), (\"seat_estimates\", seat_estimates),\n",
    "                 (\"wlan_clients\", wlan_clients), (\"manual_counts\", manual_counts)]:\n",
    "    if df is None:\n",
    "        print(f\"{name}: not found in Dump\")\n",
    "    else:\n",
    "        print(f\"{name}: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f921d60",
   "metadata": {},
   "source": [
    "\n",
    "## Typen konvertieren\n",
    "\n",
    "- `timestamp` → `datetime` (naiv, als Europe/Berlin interpretierbar)\n",
    "- numerische Spalten → `int/float`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3817f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion finished.\n"
     ]
    }
   ],
   "source": [
    "def to_datetime_safe(s):\n",
    "    return pd.to_datetime(s, errors=\"coerce\")\n",
    "\n",
    "def to_int_safe(s):\n",
    "    return pd.to_numeric(s, errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "def to_float_safe(s):\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "# locations\n",
    "if locations is not None:\n",
    "    for c in [\"id\", \"availableseats\", \"superlocation_id\"]:\n",
    "        if c in locations.columns:\n",
    "            locations[c] = to_int_safe(locations[c])\n",
    "    if \"timestamp\" in locations.columns:\n",
    "        locations[\"timestamp\"] = to_datetime_safe(locations[\"timestamp\"])\n",
    "\n",
    "# seat_estimates\n",
    "if seat_estimates is not None:\n",
    "    for c in [\"id\", \"location_id\", \"occupiedseats\", \"freeseats\"]:\n",
    "        if c in seat_estimates.columns:\n",
    "            seat_estimates[c] = to_int_safe(seat_estimates[c])\n",
    "    if \"timestamp\" in seat_estimates.columns:\n",
    "        seat_estimates[\"timestamp\"] = to_datetime_safe(seat_estimates[\"timestamp\"])\n",
    "\n",
    "# wlan_clients\n",
    "if wlan_clients is not None:\n",
    "    for c in [\"id\", \"location_id\", \"numberofclients\"]:\n",
    "        if c in wlan_clients.columns:\n",
    "            wlan_clients[c] = to_int_safe(wlan_clients[c])\n",
    "    if \"timestamp\" in wlan_clients.columns:\n",
    "        wlan_clients[\"timestamp\"] = to_datetime_safe(wlan_clients[\"timestamp\"])\n",
    "\n",
    "# manual_counts\n",
    "if manual_counts is not None:\n",
    "    for c in [\"id\", \"location_id\", \"occupiedseats\", \"freeseats\"]:\n",
    "        if c in manual_counts.columns:\n",
    "            manual_counts[c] = to_int_safe(manual_counts[c])\n",
    "    if \"timestamp\" in manual_counts.columns:\n",
    "        manual_counts[\"timestamp\"] = to_datetime_safe(manual_counts[\"timestamp\"])\n",
    "\n",
    "# Nützliche Lookup-Infos\n",
    "if locations is not None:\n",
    "    loc_lookup = locations.set_index(\"id\")[[\"name\",\"longname\",\"availableseats\"]]\n",
    "else:\n",
    "    loc_lookup = pd.DataFrame()\n",
    "\n",
    "print(\"Conversion finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967d9471",
   "metadata": {},
   "source": [
    "\n",
    "## CSV-Exporte\n",
    "\n",
    "Praktisch, wenn man die Aggregationen außerhalb des Notebooks prüfen möchte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c56403df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV-Exporte in: exports\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = \"exports\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "if locations is not None: locations.to_csv(os.path.join(OUTDIR, \"locations.csv\"), index=False)\n",
    "if seat_estimates is not None: seat_estimates.to_csv(os.path.join(OUTDIR, \"seat_estimates.csv\"), index=False)\n",
    "if wlan_clients is not None: wlan_clients.to_csv(os.path.join(OUTDIR, \"wlan_clients.csv\"), index=False)\n",
    "if manual_counts is not None: manual_counts.to_csv(os.path.join(OUTDIR, \"manual_counts.csv\"), index=False)\n",
    "\n",
    "print(\"CSV-Exporte in:\", OUTDIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl_env)\n",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
